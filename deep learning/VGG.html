<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="./main.css">
    <title>Document</title>
</head>

<body>
    <div class="contain">
        <div class="one">
            VGG是Oxford的Visual Geometry Group的组提出的（大家应该能看出VGG名字的由来了）。
            该网络是在ILSVRC 2014上的相关工作，主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能。
            VGG有两种结构，分别是VGG16和VGG19，两者并没有本质上的区别，只是网络深度不一样。
            <div class="image">
                <!-- <img src="https://mp-626c1475-9454-4b28-bba0-54f2cc7c0561.cdn.bspapp.com/Net/vgg.jpg" alt=""> -->

            </div>
            <!-- 概念&发展 -->
        </div>
        <div class="two">
            改进：<br>
            VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，
            因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。<br>

            简单来说，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，
            这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。<br>

            比如，3个步长为1的3x3卷积核的一层层叠加作用可看成一个大小为7的感受野（其实就表示3个3x3连续卷积相当于一个7x7卷积），其参数总量为 3x(9xC^2) ，
            如果直接使用7x7卷积核，其参数总量为 49xC^2 ，
            这里 C 指的是输入和输出的通道数。很明显，27xC^2小于49xC^2，即减少了参数；而且3x3卷积核有利于更好地保持图像性质。
            优点：<br>
            1.VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。<br>
            2.几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好：<br>
            3.验证了通过不断加深网络结构可以提升性能。<br>
            缺点：<br>
            VGG耗费更多计算资源，并且使用了更多的参数（这里不是3x3卷积的锅），导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。VGG可是有3个全连接层啊！<br>

            <!-- 优点 -->
        </div>
        <div class="three">
            <div class="code_block">
                turdfystyst
            </div>
        </div>
    </div>
</body>

</html>